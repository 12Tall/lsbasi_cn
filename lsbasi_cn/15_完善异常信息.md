15_å®Œå–„é”™è¯¯ä¿¡æ¯    

ğŸ“… 2019-06-21  

> â€œæˆ‘èµ°å¾—å¾ˆæ…¢ï¼Œä½†æˆ‘ä»ä¸åé€€â€ â€”â€” äºšä¼¯æ‹‰ç½•Â·æ—è‚¯    

ç°åœ¨æˆ‘ä»¬å›å½’æ­£å¸¸çš„ç¼–ç¨‹æ—¥ç¨‹ï¼:)  

åœ¨å¼€å§‹è¯†åˆ«å’Œè§£é‡Šè¿‡ç¨‹è°ƒç”¨çš„è¯é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥æ”¹è¿›ä¸€ä¸‹æˆ‘ä»¬ç°æœ‰ä»£ç çš„é”™è¯¯æç¤ºéƒ¨åˆ†ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œå½“æˆ‘ä»¬çš„ç¼–è¯‘å™¨åœ¨è¯æ³•åˆ†æã€è¯­æ³•åˆ†ææˆ–è€…è¯­ä¹‰åˆ†æä¸­é‡åˆ°é”™è¯¯æ—¶ï¼Œå°±ä¼šç›´æ¥æŠ›å‡ºä¸€ä¸ªé€šç”¨çš„å¼‚å¸¸å¹¶å°†å †æ ˆè¿½è¸ªçš„ä¿¡æ¯ä¸€å¹¶ç»™å‡ºã€‚ç„¶è€Œæˆ‘ä»¬å¯ä»¥åšå¾—æ›´å¥½ï¼  

ä¸ºäº†èƒ½æ›´åŠ ç²¾ç¡®åœ°å®šä½ä»£ç ä¸­å‡ºç°é—®é¢˜çš„ä½ç½®ï¼Œæˆ‘ä»¬éœ€è¦ç»™è§£é‡Šå™¨/ç¼–è¯‘å™¨åŠ ä¸€äº›æ–°çš„ç‰¹æ€§ï¼Œé¡ºä¾¿ä¹Ÿå¯ä»¥åšä¸€äº›å…¶ä»–çš„æ”¹è¿›ã€‚è¿™å°†è®©æˆ‘ä»¬çš„è§£é‡Šå™¨å¯¹ç”¨æˆ·æ›´åŠ å‹å¥½ï¼Œåœ¨â€œçŸ­æš‚â€ï¼ˆä¸€å¹´ï¼‰çš„åœæ›´åå±•ç¤ºä¸€ä¸‹æˆ‘ä»¬çš„æŠ€æœ¯ï¼Œå¹¶ä¸”ä¹Ÿæœ‰åˆ©äºæˆ‘ä»¬ä»¥åå‘ç¼–è¯‘å™¨/è§£é‡Šå™¨ä¸­æ·»åŠ æ›´å¤šçš„åŠŸèƒ½ã€‚  

## ä»Šå¤©çš„ç›®æ ‡  
- æ”¹è¿›è¯æ³•åˆ†æå™¨ã€è¯­æ³•åˆ†æå™¨ã€è¯­ä¹‰åˆ†æå™¨çš„é”™è¯¯æŠ¥å‘ŠåŠŸèƒ½ã€‚ç”¨ç±»ä¼¼äº`SyntaxError: Unexpected token -> Token(TokenType.SEMI, â€˜;â€™, position=23:13)` çš„é”™è¯¯ä¿¡æ¯æ›¿ä»£é”™è¯¯æ ˆä¸­çš„`Invalid syntax`ï¼›  
- æ–°å¢`--scope` å‘½ä»¤è¡Œé€‰é¡¹ï¼Œæ¥æ§åˆ¶æ˜¯å¦æ‰“å°ä½œç”¨åŸŸçš„è°ƒè¯•ä¿¡æ¯ï¼›  
- ä»ä»Šå¤©å¼€å§‹ï¼Œæˆ‘ä»¬çš„ä»£ç å°†å…¨éƒ¨è¿ç§»è‡³Python 3ï¼Œå¹¶ä¸”æ‰€æœ‰çš„æºç åªåœ¨Python 3.7+ ä¸Šæµ‹è¯•ã€‚  

## ä¿®æ”¹è¯æ³•åˆ†æå™¨  
é¦–å…ˆä»è¯æ³•åˆ†æå™¨å…¥æ‰‹ï¼Œæ¥å±•ç¤ºä¸€ä¸‹æˆ‘ä»¬çš„ä»£ç å®åŠ›ï¼ä¸‹é¢æ˜¯éœ€è¦æ”¹åŠ¨çš„ç‚¹ï¼š  
1. æ–°å¢é”™è¯¯ç ï¼ˆError Codeï¼‰ï¼Œå’Œè‡ªå®šä¹‰å¼‚å¸¸ï¼š`LexerError`ã€`ParserError` å’Œ`SemanticError`ï¼›  
2. ç»™è¯æ³•åˆ†æå™¨æ–°å¢è®°å½•`Token` ä½ç½®çš„å±æ€§ï¼š`lineno` å’Œ`column`ï¼›  
3. æ›´æ–°`advance` æ–¹æ³•ï¼Œç”¨äºæ›´æ–°è¯æ³•åˆ†æå™¨å¯¹è±¡ä¸­çš„`lineno` å’Œ`column` å±æ€§ï¼›  
4. æ›´æ–°è¯æ³•åˆ†æå™¨ä¸­çš„`error` æ–¹æ³•ä»¥æŠ›å‡º`LexerError` çš„å¼‚å¸¸ä¿¡æ¯ï¼ˆåŒ…å«å½“å‰æ‰€åœ¨çš„è¡Œå’Œåˆ—çš„ä¿¡æ¯ï¼‰ï¼›  
5. é€šè¿‡æšä¸¾ç±»å‹å®šä¹‰`TokenType`ï¼ˆPython 3.4+ï¼‰ï¼›  
6. é€šè¿‡`TokenType` æšä¸¾ç±»å‹è‡ªåŠ¨åˆ›å»ºä¿ç•™å…³é”®å­—ï¼›  
7. ç»™Token ç±»æ–°å¢å±æ€§ï¼š`lineno` å’Œ`column`ï¼Œç”¨äºè®°å½•`token` å¯¹è±¡æ‰€åœ¨çš„è¡Œåˆ—ä¿¡æ¯ï¼›  
8. æˆ‘ä»¬ä¼šé‡æ„`get_next_token` æ–¹æ³•ï¼Œè®©ä»£ç æ›´ç®€çŸ­ï¼Œå¹¶ä¸”å†™ä¸€ä¸ªæ›´ä¸€èˆ¬çš„æ–¹æ³•æ¥å¤„ç†æ‰€æœ‰å•å­—ç¬¦çš„tokenã€‚  

æˆ‘ä»¬é¦–å…ˆæ¥å®šä¹‰ä¸€äº›é”™è¯¯ä»£ç ï¼Œè¿™äº›é”™è¯¯ä»£ç å°†ä¼šåœ¨è¯æ³•åˆ†æã€è¯­æ³•åˆ†æä»¥åŠè¯­ä¹‰åˆ†æä¸­ç”¨åˆ°ã€‚åŒæ—¶æˆ‘ä»¬ä¹Ÿå®šä¹‰å¯¹åº”çš„é”™è¯¯ç±»ï¼š`LexerError`ã€`ParserError` å’Œ`SemanticError`ï¼š  
```python
from enum import Enum

class ErrorCode(Enum):
    UNEXPECTED_TOKEN = 'Unexpected token'
    ID_NOT_FOUND     = 'Identifier not found'
    DUPLICATE_ID     = 'Duplicate id found'

class Error(Exception):
    def __init__(self, error_code=None, token=None, message=None):
        self.error_code = error_code
        self.token = token
        # add exception class name before the message
        self.message = f'{self.__class__.__name__}: {message}'

class LexerError(Error):
    pass

class ParserError(Error):
    pass

class SemanticError(Error):
    pass
```

`ErrorCode` æ˜¯ä¸€ä¸ªæšä¸¾ç±»å‹ï¼Œæ¯ä¸ªæšä¸¾å±æ€§éƒ½å…·æœ‰ä¸€ä¸ªå€¼ï¼š  
```shell-session
>>> from enum import Enum
>>>
>>> class ErrorCode(Enum):
...     UNEXPECTED_TOKEN = 'Unexpected token'
...     ID_NOT_FOUND     = 'Identifier not found'
...     DUPLICATE_ID     = 'Duplicate id found'
...
>>> ErrorCode
<enum 'ErrorCode'>
>>>
>>> ErrorCode.ID_NOT_FOUND
<ErrorCode.ID_NOT_FOUND: 'Identifier not found'>
```  

`Error` åŸºç±»çš„æ„é€ å‡½æ•°æ¥å—ä¸‰ä¸ªå‚æ•°ï¼š  
- `error_code`ï¼šæšä¸¾ç±»å‹  
- `token`ï¼šToken çš„å®ä¾‹å¯¹è±¡  
- `message`ï¼šæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯  

æ­£å¦‚ä¹‹å‰æ‰€æåˆ°çš„ï¼Œ`LexerError` ç”¨æ¥ä¸“æŒ‡è¯æ³•åˆ†æå™¨çš„é”™è¯¯ï¼Œ`ParserError` ç”¨æ¥ä»£è¡¨è¯­æ³•åˆ†æå™¨çš„é”™è¯¯ï¼Œè€Œ`SemanticError` ç”¨æ¥è¡¨ç¤ºè¯­ä¹‰åˆ†æä¸­é‡åˆ°çš„é”™è¯¯ã€‚  

ç„¶åä¸ºäº†æ›´å¥½åœ°è¡¨ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦è·å–é”™è¯¯åœ¨æºä»£ç ä¸­çš„ä½ç½®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¯æ³•åˆ†æå™¨ç”Ÿæˆ`token` æ—¶æ·»åŠ å½“å‰è¡Œå’Œåˆ—çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ä¼šä¸€ç›´éšç€`token`ï¼š  
```python
class Lexer(object):
    def __init__(self, text):
        ...
        # self.pos is an index into self.text
        self.pos = 0
        self.current_char = self.text[self.pos]
        # token line number and column number
        self.lineno = 1
        self.column = 1
```

ä¸‹ä¸€æ­¥æˆ‘ä»¬éœ€è¦åœ¨é‡åˆ°æ¢è¡Œç¬¦æ—¶é‡æ–°è®¾ç½®`lineno` å’Œ`column` è®¡æ•°ï¼Œ`self.pos` ä¾ç„¶éœ€è¦è‡ªå¢1ï¼š  
```python
def advance(self):
    """Advance the `pos` pointer and set the `current_char` variable."""
    if self.current_char == '\n':
        self.lineno += 1
        self.column = 0

    self.pos += 1
    if self.pos > len(self.text) - 1:
        self.current_char = None  # Indicates end of input
    else:
        self.current_char = self.text[self.pos]
        self.column += 1
```  
é€šè¿‡ä»¥ä¸Šæ”¹åŠ¨ï¼Œè¯æ³•åˆ†æå™¨äº§ç”Ÿçš„æ¯ä¸€ä¸ª`Token` éƒ½ä¼šå¸¦æœ‰å…¶åœ¨æºé©¬ä¸­çš„è¡Œå’Œåˆ—çš„ä¿¡æ¯ã€‚  

æœ€åæ˜¯æŠ›å‡ºå¼‚å¸¸çš„`error` æ–¹æ³•ï¼Œå› ä¸ºæ˜¯åœ¨ç”Ÿæˆ`token` æ—¶é‡åˆ°å¼‚å¸¸ï¼Œæ‰€ä»¥ä¸ä¼šåŒ…å«`token` ä¿¡æ¯ï¼š  
```python
def error(self):
    s = "Lexer error on '{lexeme}' line: {lineno} column: {column}".format(
        lexeme=self.current_char,
        lineno=self.lineno,
        column=self.column,
    )
    raise LexerError(message=s)
```

ä»¥ä¸Šæ˜¯`LexerError` å¼‚å¸¸å¤„ç†çš„éƒ¨åˆ†ã€‚ä¸‹é¢æˆ‘ä»¬æƒ³åˆ©ç”¨æšä¸¾ç±»é‡æ„ä¸€ä¸‹`Token` ç±»å‹ç›¸å…³çš„ä»£ç ï¼Œå› ä¸ºç›®å‰å®ƒä»¬éƒ½æ˜¯ä»¥æ¨¡å—å˜é‡çš„å½¢å¼å†™åœ¨æºæ–‡ä»¶ä¸­çš„ã€‚æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª`TokenType` ç±»ï¼Œåé¢å¯ä»¥çœ‹åˆ°å®ƒå°†æœ‰åˆ©äºæˆ‘ä»¬ç®€åŒ–ä»£ç ã€‚  

è¿™æ˜¯ç›®å‰çš„ä»£ç é£æ ¼ï¼š  
```python
# Token types
PLUS  = 'PLUS'
MINUS = 'MINUS'
MUL   = 'MUL'
...
```  

è¿™æ˜¯æ–°çš„ä»£ç é£æ ¼ï¼š
```python
# è¯‘æ³¨ï¼š
# Python ä¸­çš„æšä¸¾å±æ€§æ˜¯æŒ‰å®šä¹‰æ—¶çš„é¡ºåºæ’åˆ—çš„ï¼Œæ‰€ä»¥å¯ä»¥æ”¾å¿ƒåœ°è¿›è¡Œéå†æ“ä½œ  
class TokenType(Enum):
    # single-character token types
    PLUS          = '+'
    MINUS         = '-'
    MUL           = '*'
    FLOAT_DIV     = '/'
    LPAREN        = '('
    RPAREN        = ')'
    SEMI          = ';'
    DOT           = '.'
    COLON         = ':'
    COMMA         = ','
    # block of reserved words
    PROGRAM       = 'PROGRAM'  # marks the beginning of the block
    INTEGER       = 'INTEGER'
    REAL          = 'REAL'
    INTEGER_DIV   = 'DIV'
    VAR           = 'VAR'
    PROCEDURE     = 'PROCEDURE'
    BEGIN         = 'BEGIN'
    END           = 'END'      # marks the end of the block
    # misc
    ID            = 'ID'
    INTEGER_CONST = 'INTEGER_CONST'
    REAL_CONST    = 'REAL_CONST'
    ASSIGN        = ':='
    EOF           = 'EOF'
```

è¿‡å»åœ¨æ·»åŠ æ–°çš„`token` ç±»å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åˆ›å»º`RESERVED_KEYWORDS` å…³é”®å­—å­—å…¸ï¼Œä¾‹å¦‚ï¼š  
- a. é¦–å…ˆåœ¨æ¨¡å—å±‚é¢å£°æ˜å˜é‡ï¼š`STRING = 'STRING'`  
- b. ç„¶åå°†å…¶æ‰‹å·¥æ·»åŠ è¿›`RESERVED_KEYWORDS` å­—å…¸ä¸­  

ç°åœ¨æˆ‘ä»¬æœ‰äº†TokenType æšä¸¾ç±»å‹ï¼Œå°±å¯ä»¥è®©æ­¥éª¤b è‡ªåŠ¨æ‰§è¡Œäº†ã€‚è¿™å°±æ˜¯[two is too many](https://www.codesimplicity.com/post/two-is-too-many/) è§„åˆ™ã€‚ä»Šåæ·»åŠ `token` ç±»å‹æ—¶ï¼Œæˆ‘ä»¬åªéœ€åœ¨`TokenType` ç±»çš„`PROGRAM` å’Œ`END` å…³é”®å­—ä¹‹é—´æ·»åŠ å¯¹åº”çš„å…³é”®å­—å°±å¥½äº†ï¼Œå‰©ä¸‹çš„äº‹æƒ…`_build_reserved_keywords` æ–¹æ³•ä¼šå¸®æˆ‘ä»¬å¤„ç†ï¼š   
```python  
def _build_reserved_keywords():
    """Build a dictionary of reserved keywords.

    The function relies on the fact that in the TokenType
    enumeration the beginning of the block of reserved keywords is
    marked with PROGRAM and the end of the block is marked with
    the END keyword.

    Result:
        {'PROGRAM': <TokenType.PROGRAM: 'PROGRAM'>,
         'INTEGER': <TokenType.INTEGER: 'INTEGER'>,
         'REAL': <TokenType.REAL: 'REAL'>,
         'DIV': <TokenType.INTEGER_DIV: 'DIV'>,
         'VAR': <TokenType.VAR: 'VAR'>,
         'PROCEDURE': <TokenType.PROCEDURE: 'PROCEDURE'>,
         'BEGIN': <TokenType.BEGIN: 'BEGIN'>,
         'END': <TokenType.END: 'END'>}
    """
    # enumerations support iteration, in definition order
    tt_list = list(TokenType)  # æƒ³æƒ³æšä¸¾å±æ€§çš„å®šä¹‰é¡ºåº
    start_index = tt_list.index(TokenType.PROGRAM)
    end_index = tt_list.index(TokenType.END)
    reserved_keywords = {  # å­—å…¸æ¨å¯¼å¼ï¼Œè¯­æ³•ç³–
        token_type.value: token_type
        for token_type in tt_list[start_index:end_index + 1]
    }
    return reserved_keywords


RESERVED_KEYWORDS = _build_reserved_keywords()
```
ä»ä¸Šé¢å‡½æ•°çš„è¯´æ˜æ–‡æ¡£ä¸­å¯ä»¥çœ‹å‡ºï¼Œç”Ÿæˆå­—å…¸çš„å†…å®¹ä¾èµ–äº`TokenType` ä¸­å®šä¹‰åœ¨`PROGRAM` å’Œ`END` å…³é”®å­—ä¹‹é—´çš„å†…å®¹ã€‚è¯¥æ–¹æ³•é¦–å…ˆå°†`TokenType` è½¬åŒ–ä¸ºä¸€ä¸ª`list`ï¼ˆæ³¨æ„å…ƒç´ ä¸å®šä¹‰é¡ºåºç›¸åŒï¼‰ï¼Œç„¶åè·å–`PROGRAM` å’Œ`END` å…³é”®å­—çš„ç´¢å¼•ï¼Œæœ€åæ ¹æ®ç´¢å¼•ï¼Œåˆ©ç”¨å­—å…¸æ¨å¯¼å¼çš„ç‰¹æ€§æ¥åˆ›å»ºä¿ç•™å…³é”®å­—çš„å­—å…¸ï¼š  
```shell-session
>>> from spi import _build_reserved_keywords
>>> from pprint import pprint
>>> pprint(_build_reserved_keywords())  # 'pprint' sorts the keys
{'BEGIN': <TokenType.BEGIN: 'BEGIN'>,
 'DIV': <TokenType.INTEGER_DIV: 'DIV'>,
 'END': <TokenType.END: 'END'>,
 'INTEGER': <TokenType.INTEGER: 'INTEGER'>,
 'PROCEDURE': <TokenType.PROCEDURE: 'PROCEDURE'>,
 'PROGRAM': <TokenType.PROGRAM: 'PROGRAM'>,
 'REAL': <TokenType.REAL: 'REAL'>,
 'VAR': <TokenType.VAR: 'VAR'>}
```  

æ¥ä¸‹æ¥æ˜¯æ›´æ–°`Token` ç±»ï¼Œæ–°å¢`lineno` å’Œ`column` å±æ€§ï¼š  
```python
class Token(object):
    def __init__(self, type, value, lineno=None, column=None):
        self.type = type
        self.value = value
        self.lineno = lineno
        self.column = column

    def __str__(self):
        """String representation of the class instance.

        Example:
            >>> Token(TokenType.INTEGER, 7, lineno=5, column=10)
            Token(TokenType.INTEGER, 7, position=5:10)
        """
        return 'Token({type}, {value}, position={lineno}:{column})'.format(
            type=self.type,
            value=repr(self.value),
            lineno=self.lineno,
            column=self.column,
        )

    def __repr__(self):
        return self.__str__()
```

æœ€åè¿›å…¥`get_next_token` æ–¹æ³•ã€‚å› ä¸ºPython ä¸­æšä¸¾çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åˆ›å»ºå•å­—ç¬¦`token` æ—¶å‡å°‘å¤§é‡çš„å†—ä½™ä»£ç ã€‚  
è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰çš„é£æ ¼ï¼š  
```python
if self.current_char == ';':
    self.advance()
    return Token(SEMI, ';')

if self.current_char == ':':
    self.advance()
    return Token(COLON, ':')

if self.current_char == ',':
    self.advance()
    return Token(COMMA, ',')
...
```  

ç°åœ¨æˆ‘ä»¬å¯ä»¥é‡‡ç”¨æ›´ä¸€èˆ¬çš„ä»£ç æ¥å¤„ç†æ‰€æœ‰å•å­—ç¬¦çš„`token` äº†ï¼š  
```python  
# single-character token
try:
    # get enum member by value, e.g.
    # TokenType(';') --> TokenType.SEMI
    token_type = TokenType(self.current_char)
except ValueError:
    # no enum member with value equal to self.current_char
    self.error()
else:
    # create a token with a single-character lexeme as its value
    token = Token(
        type=token_type,
        value=token_type.value,  # e.g. ';', '.', etc
        lineno=self.lineno,
        column=self.column,
    )
    self.advance()
    return token  
"""
è¯‘æ³¨ï¼š  
1) æ­¤ä»£ç æ˜¯æ”¾åœ¨æ‰€æœ‰å¤šå­—ç¬¦token å¤„ç†çš„æœ€åé¢çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å¦‚æœè¿™æ®µä»£ç èµ°å®Œè¿˜æ²¡æœ‰è¯†åˆ«å‡ºtokenï¼Œå°±è‚¯å®šæ˜¯å‡ºé”™äº†ã€‚  
2) è™½ç„¶æ­¤ä»£ç åŠŸèƒ½ä¸Šæ²¡é—®é¢˜ï¼Œä½†æ˜¯ä½¿ç”¨try-catch åšåˆ¤æ–­è¿™ä¸€è¡Œä¸ºæ˜¯æä¸æ¨èçš„ï¼Œå› ä¸ºå¼‚å¸¸å¤„ç†ä¼šæå¤§çš„ç‰ºç‰²ä»£ç æ€§èƒ½ï¼è¿™é‡Œå¯ä»¥ä»¿æ•ˆç”Ÿæˆä¿ç•™å­—å­—å…¸ä¸€æ ·ï¼Œç”Ÿæˆå•å­—ç¬¦token çš„å­—å…¸è¿›è¡Œå¤„ç†ã€‚  
3) å¦‚æœæƒ³è¦å…¼å®¹å¤šå­—ç¬¦çš„ä¿¡æ¯ï¼Œå¯èƒ½çŠ¶æ€æœºä¹Ÿæ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚    
"""
```  

æŒ‰ç†è¯´ï¼Œ`if` ä»£ç å—çš„å¯è¯»æ€§è¦æ›´é«˜ä¸€äº›ï¼Œä½†æ˜¯å½“ä½ ç†è§£äº†ä¸Šè¿°ä»£ç ä¹‹åï¼Œä½ ä¼šå‘ç°åŸç†éå¸¸ç®€å•ã€‚Python å…è®¸æˆ‘ä»¬é€šè¿‡æšä¸¾çš„å€¼æ‰¾åˆ°æšä¸¾çš„æˆå‘˜ï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥ï¼š  
- è¯•å›¾é€šè¿‡å½“å‰å­—ç¬¦æŸ¥æ‰¾å…¶åœ¨æšä¸¾ä¸­æ˜¯å¦æœ‰å®šä¹‰  
- å¦‚æœæ²¡æœ‰å°±æŠ›å‡ºå¼‚å¸¸  
- å¦‚æœæœ‰å°±è¿”å›ä¸€ä¸ªå•å­—ç¬¦`token`  

è¿™ä¸ªä»£ç å—å°†ä¼šå¤„ç†æ‰€æœ‰å•å­—ç¬¦çš„`token`ï¼Œæˆ‘ä»¬æ‰€éœ€è¦åšçš„ä»…ä»…æ˜¯å‘æšä¸¾ç±»å‹ä¸­æ·»åŠ æ–°çš„å®šä¹‰å³å¯ã€‚  

çœ‹åˆ°æ²¡ï¼Œè¿™å…¶å®æ˜¯ä¸€ä¸ªåŒèµ¢çš„å±€é¢ï¼šæˆ‘ä»¬å­¦ä¹ äº†Python çš„æšä¸¾ç±»å‹ï¼Œå°¤å…¶æ˜¯å¦‚ä½•é€šè¿‡å€¼è®¿é—®æšä¸¾æˆå‘˜ï¼›è¿˜å†™å‡ºäº†å¤„ç†å•å­—ç¬¦`token` çš„é€šç”¨æ–¹æ³•ï¼Œå¹¶ä¸”å‡å°‘äº†å¾ˆå¤šå†—ä½™ä»£ç ã€‚  


## è¯­æ³•åˆ†æå™¨  
ä¸Šé¢æ˜¯è¯æ³•åˆ†æå™¨çš„ä¿®æ”¹ï¼Œä¸‹é¢æˆ‘ä»¬æ¥çœ‹è¯­æ³•åˆ†æå™¨çš„ï¼š  
1. æ›´æ–°è¯­æ³•åˆ†æå™¨`error` æ–¹æ³•ï¼Œä½¿å…¶å¯ä»¥æŠ›å‡º`ParserError` å¼‚å¸¸ï¼ˆåŒ…å«`token` ä¿¡æ¯ï¼‰  
2. æ›´æ–°`eat` æ–¹æ³•ï¼Œä½¿ä¹‹èƒ½è°ƒç”¨æ–°çš„`error` æ–¹æ³•  
3. é‡æ„`declarations` æ–¹æ³•ï¼Œå°†è¿‡ç¨‹å£°æ˜éƒ¨åˆ†å•ç‹¬æå–ä¸º`procedure_declaration`   

é¦–å…ˆï¼Œæˆ‘ä»¬æ›´æ–°error æ–¹æ³•ï¼š  
```python
def error(self, error_code, token):
    raise ParserError(
        error_code=error_code,
        token=token,
        message=f'{error_code.value} -> {token}',
    )
```  

ç„¶åæ˜¯`eat` æ–¹æ³•ï¼Œ`token` ç±»å‹ä¸åŒ¹é…åˆ™æŠ¥é”™ï¼š  
```python
def eat(self, token_type):
    # compare the current token type with the passed token
    # type and if they match then "eat" the current token
    # and assign the next token to the self.current_token,
    # otherwise raise an exception.
    if self.current_token.type == token_type:
        self.current_token = self.get_next_token()
    else:
        self.error(
            error_code=ErrorCode.UNEXPECTED_TOKEN,
            token=self.current_token,
        )
```  

æœ€åæ˜¯æå–`procedure_declaration` éƒ¨åˆ†ï¼š  
```python  
def declarations(self):
    """
    declarations : (VAR (variable_declaration SEMI)+)? procedure_declaration*
    """
    declarations = []

    if self.current_token.type == TokenType.VAR:
        self.eat(TokenType.VAR)
        while self.current_token.type == TokenType.ID:
            var_decl = self.variable_declaration()
            declarations.extend(var_decl)
            self.eat(TokenType.SEMI)

    while self.current_token.type == TokenType.PROCEDURE:
        proc_decl = self.procedure_declaration()
        declarations.append(proc_decl)

    return declarations

def procedure_declaration(self):
    """procedure_declaration :
         PROCEDURE ID (LPAREN formal_parameter_list RPAREN)? SEMI block SEMI
    """
    self.eat(TokenType.PROCEDURE)
    proc_name = self.current_token.value
    self.eat(TokenType.ID)
    params = []

    if self.current_token.type == TokenType.LPAREN:
        self.eat(TokenType.LPAREN)
        params = self.formal_parameter_list()
        self.eat(TokenType.RPAREN)

    self.eat(TokenType.SEMI)
    block_node = self.block()
    proc_decl = ProcedureDecl(proc_name, params, block_node)
    self.eat(TokenType.SEMI)
    return proc_decl
```  

ä»¥ä¸Šæ˜¯æ‰€æœ‰è¯­æ³•åˆ†æå™¨çš„æ”¹åŠ¨ï¼Œä¸‹é¢çœ‹è¯­ä¹‰åˆ†æå™¨çš„ã€‚  

## è¯­ä¹‰åˆ†æå™¨  
æœ€ç»ˆï¼Œè¯­ä¹‰åˆ†æå™¨çš„æ”¹åŠ¨å¦‚ä¸‹ï¼š  
1. æ–°å¢`error` æ–¹æ³•ï¼Œç”¨äºæŠ›å‡ºè¯­ä¹‰å¼‚å¸¸  
2. æ›´æ–°`visit_VarDecl` æ–¹æ³•ï¼Œä»¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨é‡å¤å£°æ˜  
3. æ›´æ–°`visit_Var` æ–¹æ³•ï¼Œä»¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœªç»å£°æ˜çš„å˜é‡è°ƒç”¨  
4. ç»™`ScopedSymbolTable` å’Œ`SemanticAnalyzer` å¢åŠ `log` æ–¹æ³•æ‰“å°è°ƒè¯•ä¿¡æ¯  
5. é€šè¿‡ç»™å‘½ä»¤è¡Œå¢å‡`--scope` é€‰é¡¹ï¼Œä»¥æ§åˆ¶`log` å‡½æ•°çš„å¼€å…³  
6. æ·»åŠ ç©ºæ–¹æ³•`visit_Num` å’Œ`visit_UnaryOp`  

é¦–å…ˆï¼Œæˆ‘ä»¬æ·»åŠ `error` æ–¹æ³•ï¼Œä»¥æŠ›å‡ºè¯­ä¹‰é”™è¯¯ï¼š  
```python
def error(self, error_code, token):
    raise SemanticError(
        error_code=error_code,
        token=token,
        message=f'{error_code.value} -> {token}',
    )
```

ç„¶åä¿®æ”¹`visit_VarDecl` ä»¥æ£€æŸ¥é‡å¤å£°æ˜çš„è¯­ä¹‰é”™è¯¯ï¼š  
```python  
def visit_VarDecl(self, node):
    type_name = node.type_node.value
    type_symbol = self.current_scope.lookup(type_name)

    # We have all the information we need to create a variable symbol.
    # Create the symbol and insert it into the symbol table.
    var_name = node.var_node.value
    var_symbol = VarSymbol(var_name, type_symbol)

    # Signal an error if the table already has a symbol
    # with the same name
    if self.current_scope.lookup(var_name, current_scope_only=True):
        self.error(
            error_code=ErrorCode.DUPLICATE_ID,
            token=node.var_node.token,
        )

    self.current_scope.insert(var_symbol)
```  

åŒæ ·åœ°ï¼Œæ›´æ–°`visit_Var` æ–¹æ³•ï¼š  
```python  
def visit_Var(self, node):
    var_name = node.value
    var_symbol = self.current_scope.lookup(var_name)
    if var_symbol is None:
        self.error(error_code=ErrorCode.ID_NOT_FOUND, token=node.token)
```  

è¯­ä¹‰å¼‚å¸¸å°†ä¼šä»¥ä¸‹é¢çš„æ ¼å¼æ‰“å°  
```shel-session  
SemanticError: Duplicate id found -> Token(TokenType.ID, 'a', position=21:4)  
## æˆ–è€… ##
SemanticError: Identifier not found -> Token(TokenType.ID, 'b', position=22:9)
```  

æ¥ç€ï¼Œæˆ‘ä»¬ç»™`ScopedSymbolTable` å’Œ`SemanticAnalyzer` å¢åŠ `log` æ–¹æ³•æ¥æ›¿æ¢`print` è¯­å¥ï¼š  
```python  
def log(self, msg):
    if _SHOULD_LOG_SCOPE:
        print(msg)
```  
å¯ä»¥çœ‹åˆ°ï¼Œåªæœ‰å½“å…¨å±€å˜é‡`_SHOULD_LOG_SCOPE` ä¸ºçœŸæ—¶ï¼Œé”™è¯¯ä¿¡æ¯æ‰ä¼šè¢«æ‰“å°ã€‚è€Œæˆ‘ä»¬å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ï¼Œé€šè¿‡æŒ‡å®šå‚æ•°`--scope` æ¥è®¾ç½®æ­¤å˜é‡ä¸ºçœŸï¼š  
```python  
parser = argparse.ArgumentParser(  # python çš„æ ‡å‡†åº“ä¸­
    description='SPI - Simple Pascal Interpreter'
)
parser.add_argument('inputfile', help='Pascal source file')
parser.add_argument(
    '--scope',
    help='Print scope information',
    action='store_true',  # ä¸€æ—¦æ£€æµ‹åˆ°è¯¥å‚æ•°å°±è®¾ç½®ä¸ºçœŸ
)
args = parser.parse_args()
global _SHOULD_LOG_SCOPE
_SHOULD_LOG_SCOPE = args.scope
```  
å®é™…è¿è¡Œæƒ…å†µå¦‚ä¸‹ï¼š  
```shell-session  
$ python spi.py idnotfound.pas --scope
ENTER scope: global
Insert: INTEGER
Insert: REAL
Lookup: INTEGER. (Scope name: global)
Lookup: a. (Scope name: global)
Insert: a
Lookup: b. (Scope name: global)
SemanticError: Identifier not found -> Token(TokenType.ID, 'b', position=6:9)
```  
é»˜è®¤æƒ…å†µä¸‹log åŠŸèƒ½æ˜¯å…³é—­çš„ï¼š  
```shell-session  
$ python spi.py idnotfound.pas
SemanticError: Identifier not found -> Token(TokenType.ID, 'b', position=6:9)
```

æœ€åæ·»åŠ ç©ºæ–¹æ³•`visit_Num` å’Œ`visit_UnaryOp`    
```python  
def visit_Num(self, node):
    pass

def visit_UnaryOp(self, node):
    pass
```  

ä»¥ä¸Šæ˜¯è¯­ä¹‰åˆ†æå™¨çš„æ‰€æœ‰æ”¹åŠ¨éƒ¨åˆ†ã€‚  

ä»[GitHub](https://github.com/rspivak/lsbasi/tree/master/part15/) å¯ä»¥ä¸‹è½½åŒ…å«å„ç§ç±»å‹çš„é”™è¯¯çš„Pascal æºç ï¼Œå¯ä»¥è¯•ç€ç”¨æ–°çš„è§£é‡Šå™¨éªŒè¯ä¸€ä¸‹ï¼Œçœ‹ä¼šäº§ç”Ÿä»€ä¹ˆæ ·çš„é”™è¯¯ä¿¡æ¯ã€‚  

ä»¥ä¸Šå°±æ˜¯ä»Šå¤©çš„å…¨éƒ¨å†…å®¹ï¼Œä½ å¯ä»¥åœ¨ä¸Šé¢GitHub çš„ä»“åº“ä¸­æ‰¾åˆ°æœ¬æ–‡æ‰€æœ‰çš„ä»£ç ã€‚ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†ä¼šä»‹ç»å¦‚ä½•è¯†åˆ«/è§£æè¿‡ç¨‹è°ƒç”¨ã€‚æ•¬è¯·æœŸå¾…ï¼Œå†è§ï¼

-----  
2022-07-12 18:10